
.bucket-upload-rule:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'

.bucket-upload-rule-always:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'
      when: always

.bucket-upload-rule-clone-repo:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
      when: always

cloning-repositories-upload-flow:
  stage: .pre
  extends:
    - .bucket-upload-rule-clone-repo
    - .cloning-repositories
  script:
    - job-done

.upload_packs_to_the_marketplace: &upload_packs_to_the_marketplace
  - section_start "Upload Packs To Marketplace Storage"
  - |
    if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "$GCS_PRODUCTION_BUCKET" ]]; then
      EXTRACT_FOLDER=$(mktemp -d)
      PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
      PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
      CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
      GCS_BUILD_BUCKET="marketplace-ci-build-xsoar-dev"
      if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi

      if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
        PACKS_TO_UPLOAD="All"
      fi

      python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar --artifacts-folder-server-type "${ARTIFACTS_FOLDER_SERVER_TYPE}"

      core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
      if [ "${core_packs_files_count}" -eq 0 ]; then
        echo "No core packs files were found, skipping uploading."
      else
        echo "Uploading ${core_packs_files_count} core packs files."
        # Copy core packs files from the artifacts folder to the build bucket:
        find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_BUCKET/$STORAGE_BASE_PATH/packs" \;
        echo "Successfully uploaded core packs files."
      fi
    fi
  - section_end "Upload Packs To Marketplace Storage"

.upload_packs_to_the_marketplace_xsoar_saas: &upload_packs_to_the_marketplace_xsoar_saas
  - section_start "Upload Packs To Marketplace Storage"
  - |
    if [[ "$CI_COMMIT_BRANCH" == "master" ]] ||  [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" != "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
      EXTRACT_FOLDER=$(mktemp -d)
      PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
      PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
      CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
      GCS_BUILD_BUCKET="marketplace-ci-build-xsoar-saas-dev"
      if [[ -z $STORAGE_BASE_PATH ]]; then
        if [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" == "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
          STORAGE_BASE_PATH="content"
        else
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
        fi
        echo "Set storage base path to $STORAGE_BASE_PATH"
      fi

      python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XSOAR_SAAS_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar_saas --artifacts-folder-server-type "${ARTIFACTS_FOLDER_SERVER_TYPE}"

      core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
      if [ "${core_packs_files_count}" -eq 0 ]; then
        echo "No core packs files were found, skipping uploading."
      else
        echo "Uploading ${core_packs_files_count} core packs files."
        # Copy core packs files from the artifacts folder to the build bucket:
        find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_XSOAR_SAAS_BUCKET/$STORAGE_BASE_PATH/packs" \;
        echo "Successfully uploaded core packs files."
      fi
    fi
  - section_end "Upload Packs To Marketplace Storage"

.upload_packs_to_the_marketplace_v2: &upload_packs_to_the_marketplace_v2
  - section_start "Upload Packs To Marketplace Storage"
  - |
    if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_V2_BUCKET" != "$GCS_PRODUCTION_V2_BUCKET" ]]; then
      EXTRACT_FOLDER=$(mktemp -d)
      PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
      PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
      CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
      GCS_BUILD_BUCKET="marketplace-ci-build-v2-dev"
      if [[ -z $STORAGE_BASE_PATH ]]; then
        if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]]; then
          STORAGE_BASE_PATH="content"
        else
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
        fi
        echo "Set storage base path to $STORAGE_BASE_PATH"
      fi
      if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
        PACKS_TO_UPLOAD="All"
      fi

      python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_V2_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace marketplacev2 --artifacts-folder-server-type "${ARTIFACTS_FOLDER_SERVER_TYPE}"


      core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
      if [ "${core_packs_files_count}" -eq 0 ]; then
        echo "No core packs files were found, skipping uploading."
      else
        echo "Uploading ${core_packs_files_count} core packs files."
        # Copy core packs files from the artifacts folder to the build bucket:
        find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_V2_BUCKET/$STORAGE_BASE_PATH/packs" \;
        echo "Successfully uploaded core packs files."
      fi
    fi
  - section_end "Upload Packs To Marketplace Storage"

.upload_packs_to_the_marketplace_xpanse: &upload_packs_to_the_marketplace_xpanse
  - section_start "Upload Packs To Marketplace Storage"
  - |
    if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_XPANSE_BUCKET" != "$GCS_PRODUCTION_XPANSE_BUCKET" ]]; then
      EXTRACT_FOLDER=$(mktemp -d)
      PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
      PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
      CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
      GCS_BUILD_BUCKET="marketplace-ci-build-xpanse-dev"
      if [[ -z $STORAGE_BASE_PATH ]]; then
        if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]]; then
          STORAGE_BASE_PATH="content"
        else
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
        fi
        echo "Set storage base path to $STORAGE_BASE_PATH"
      fi
      if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
        PACKS_TO_UPLOAD="All"
      fi

      python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XPANSE_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xpanse --artifacts-folder-server-type "${ARTIFACTS_FOLDER_SERVER_TYPE}"

      core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
      if [ "${core_packs_files_count}" -eq 0 ]; then
        echo "No core packs files were found, skipping uploading."
      else
        echo "Uploading ${core_packs_files_count} core packs files."
        # Copy core packs files from the artifacts folder to the build bucket:
        find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_XPANSE_BUCKET/$STORAGE_BASE_PATH/packs" \;
        echo "Successfully uploaded core packs files."
      fi
    fi
  - section_end "Upload Packs To Marketplace Storage"

.upload_content_graph: &upload_content_graph
  - section_start "Upload content graph GraphML to GCP" --collapsed
  - |
    if [[ "${TEST_UPLOAD}" == "false" ]]; then
      gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_graph/${MARKETPLACE_VERSION}.zip" "gs://${GCS_MARKET_BUCKET_DEV}/content_graph/${MARKETPLACE_VERSION}.zip"
      # copy the packs.json file to the bucket, used in contribution management
      gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs.json" "gs://${GCS_MARKET_BUCKET_DEV}/content_graph/${MARKETPLACE_VERSION}_packs.json"
    else
      echo "TEST_UPLOAD is set to true. Skipping upload_content_graph section."
    fi
  - section_end "Upload content graph GraphML to GCP"

.upload_dependencies_file: &upload_dependencies_file
  - section_start "Upload packs_dependencies.json to GCP" --collapsed
  - |
    if [[ "${TEST_UPLOAD}" == "false" ]]; then
      gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json" "gs://xsoar-ci-artifacts/content-cache-docs/${MARKETPLACE_VERSION}/packs_dependencies.json"
    else
      echo "TEST_UPLOAD is set to true. Skipping upload_dependencies_file section."
    fi
  - section_end "Upload packs_dependencies.json to GCP"

.upload_packs_results_upload: &upload_packs_results_upload
  - section_start "Upload packs results upload file"
  - |

    if [[ $TEST_UPLOAD == "false" ]] && [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" ]]; then
      gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" "gs://xsoar-ci-artifacts/content/$CI_COMMIT_SHA/$MARKETPLACE_VERSION/packs_results_upload.json"
      echo "packs_results_upload.json upload successfully"
    fi
  - section_end "Upload packs results upload file"

.upload_failed_to_upload_packs: &upload_failed_to_upload_packs
  - section_start "Upload failed_to_upload Packs" --collapsed # saves the failed-to-upload packs in content_status.json
  - |
    if [[ "${TEST_UPLOAD}" == "false" ]]; then
      CONTENT_PACKS_TO_UPLOAD_JSON=$(cat "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs_to_upload.json")
      python3 ./Tests/Marketplace/extract_and_upload_failed_packs.py -pru "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" -s "${GCS_MARKET_KEY}" -mp "${MARKETPLACE_VERSION}" -pu "${CONTENT_PACKS_TO_UPLOAD_JSON}"
    else
      echo "TEST_UPLOAD is set to true. Skipping upload_failed_to_upload_packs section."
    fi
  - section_end "Upload failed_to_upload Packs"

run-validations-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  variables:
    DEMISTO_SDK_GRAPH_FORCE_CREATE: "true"
  extends:
    - .run-validations
    - .bucket-upload-rule

run-pre-commit-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  cache:
    policy: push
  extends:
    - .run-pre-commit
    - .bucket-upload-rule
  parallel:
    matrix:
      - PRE_COMMIT_DOCKER_IMAGE:
          - "from-yml"

jobs-done-check-upload-flow:
  extends:
    - .jobs-done-check
    - .bucket-upload-rule
  needs:
    - cloning-repositories-upload-flow
    - run-pre-commit-upload-flow
    - mpv2-prepare-testing-bucket-upload-flow
    - upload-id-set-bucket
    - xpanse-prepare-testing-bucket-upload-flow
    - xsoar-prepare-testing-bucket-upload-flow
    - xsoar-saas-prepare-testing-bucket-upload-flow
    - install-packs-in-server6_11
    - install-packs-in-server6_12
    - install-packs-in-server-master
    - install-packs-in-xsiam-ga
    - install-packs-in-xsoar-ng-ga
    - sync-buckets-between-projects
    - upload-packs-to-marketplace
    - upload-packs-to-marketplace-v2
    - upload-packs-to-xpanse-marketplace
    - upload-packs-to-xsoar-saas-marketplace
    - run-validations-upload-flow
    - upload-content-graph-data-to-bigquery
  tags:
    - gke
  variables:
    WORKFLOW: 'Upload Packs to Marketplace Storage'

xsoar-prepare-testing-bucket-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  extends:
    - xsoar-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


xsoar-saas-prepare-testing-bucket-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  extends:
    - xsoar-saas-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


mpv2-prepare-testing-bucket-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  extends:
      - mpv2-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

xpanse-prepare-testing-bucket-upload-flow:
  needs:
    - cloning-repositories-upload-flow
  extends:
      - xpanse-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


.install_packs_in_xsoar_server:
  tags:
    - $BUILD_JOB_TAG
  needs:
    - xsoar-prepare-testing-bucket-upload-flow
  stage: run-instances
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_XSOAR}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately
    MARKETPLACE_NAME: "xsoar"
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - EXIT_CODE=0

    - !reference [.ssh-config-setup]
    - section_start "Check if should run Instance role"
    - export INSTANCES_CREATED_FOR_ROLE=$(cat "${ENV_RESULTS_PATH}" | jq -c "map(select(.Role == \"${INSTANCE_ROLE}\")) | length")
    - |
      echo "Instance role:${INSTANCE_ROLE} Product type:${PRODUCT_TYPE} Instances created for role:${INSTANCES_CREATED_FOR_ROLE}"
      if [[ "${INSTANCES_CREATED_FOR_ROLE}" -eq 0 ]]; then
        echo "Instances with role ${INSTANCE_ROLE} were not created, not running the instance flow."
        rm -f "${ARTIFACTS_FOLDER_INSTANCE}/instance_role.txt" # delete the instance_role.txt file so the job will not be collected by slack notifier.
        job-done
        exit 0
      fi
    - section_end "Check if should run Instance role"

    - section_start "Get Instance Variables" --collapsed
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"

    - section_start "Wait Until Server Ready"
    - python3 ./Tests/scripts/wait_until_server_ready.py  -n ${IS_NIGHTLY} --instance-role "${INSTANCE_ROLE}" || EXIT_CODE=$?
    - section_end "Wait Until Server Ready"
    - !reference [.install_packs_by_machines]
    - section_start "Create Build_Pass file"
    - |
      if [ "${EXIT_CODE}" -eq 0 ]; then
        role="$(echo -e "${INSTANCE_ROLE}" | tr -d '[:space:]')"
        is_build_passed_filepath="${ARTIFACTS_FOLDER}/is_build_passed_${role}.txt"
        is_post_update_passed_filepath="${ARTIFACTS_FOLDER}/is_post_update_passed_${role}.txt"
        echo "Build passed for instance role: ${INSTANCE_ROLE}, server type:${SERVER_TYPE} writing it passed to artifacts folder in is_build_passed:${is_build_passed_filepath} is_post_update_passed:${is_post_update_passed_filepath}"
        touch "${is_build_passed_filepath}"
        touch "${is_post_update_passed_filepath}"
      else
        echo "Build failed for instance role: ${INSTANCE_ROLE}, server type:${SERVER_TYPE} with exit code: ${EXIT_CODE}"
      fi
    - section_end "Create Build_Pass file"
    - section_start "Get instance ssh-command"
    - echo "INSTANCE_ROLE -> ${INSTANCE_ROLE}"
    - INSTANCE_NAME=$(jq -r --arg role "$INSTANCE_ROLE" '.[] | select(.Role == $role) | .InstanceName' $ENV_RESULTS_PATH)
    - echo -e "\e[1m gcloud compute ssh --zone \"us-central1-a\" \"${INSTANCE_NAME}\"  --tunnel-through-iap --project "xsoar-content-build" \e[0m"
    - section_end "Get instance ssh-command"
    - job-done
    - exit "${EXIT_CODE}"
  after_script:
    - !reference [.default-after-script]
    - !reference [.install_ssh_keys]
    - !reference [.ssh-config-setup]
    - !reference [.destroy_xsoar_instances]


install-packs-in-server6_11:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.11"

install-packs-in-server6_12:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.12"

install-packs-in-server-master:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server Master"


.install-packs-on-cloud-instances:
  tags:
     - $BUILD_JOB_TAG
  stage: run-instances
  extends:
    - .default-job-settings
    - .docker_services
  script:
    - EXIT_CODE=0

    - section_start "Lock Machine" --collapsed
    - ./Tests/scripts/lock_cloud_machines.sh
    - export CLOUD_CHOSEN_MACHINE_IDS=$(cat "${ARTIFACTS_FOLDER}/locked_machines_list.txt")
    - echo "CLOUD Chosen machine ids are:${CLOUD_CHOSEN_MACHINE_IDS}"
    - section_end "Lock Machine"

    - !reference [.uninstall-packs-and-reset-bucket-cloud]

    - section_start "Get Instance Variables" --collapsed
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"

    - !reference [.install_packs_by_machines]

    - job-done
    - exit "$EXIT_CODE"
  after_script:
    - source .gitlab/helper_functions.sh
    - !reference [.clean-machine]
    - !reference [ .unlock-machine ]


install-packs-in-xsiam-ga:
  needs:
    - job: mpv2-prepare-testing-bucket-upload-flow
  extends: .install-packs-on-cloud-instances
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: $TEST_UPLOAD == "true" && $BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "build"
        GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga"
        CLEAN_MACHINE_NEEDED: "true"
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'
  variables:
    GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga-upload"
    CLOUD_MACHINES_TYPE: "upload"
    CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">0" # don't run the job if there are no machines available.
    CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">0" # stop waiting on the timeout if we got at least one machine.
    CLOUD_MACHINES_TIMEOUT: 0  # Wait indefinitely for the machines.
    CLEAN_MACHINE_NEEDED: "true"
    INSTANCE_ROLE: "XSIAM"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_SOURCE_BUCKET: "$GCS_PRODUCTION_V2_BUCKET"
    GCS_MACHINES_BUCKET: "marketplace-v2-dist-dev/upload-flow/builds-xsiam"
    NON_REMOVABLE_PACKS: "Base"
    MARKETPLACE_NAME: "marketplacev2"
    PRODUCT_TYPE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_MPV2}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately


install-packs-in-xsoar-ng-ga:
  needs:
    - job: xsoar-saas-prepare-testing-bucket-upload-flow
  extends: .install-packs-on-cloud-instances
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: $TEST_UPLOAD == "true" && $BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "build"
        GCS_LOCKS_PATH: "content-locks/locks-xsoar-ng"
        CLEAN_MACHINE_NEEDED: "true"
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'
  variables:
    GCS_LOCKS_PATH: "content-locks/locks-xsoar-ng-upload"
    CLOUD_MACHINES_TYPE: "upload"
    CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">0" # don't run the job if there are no machines available.
    CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">0" # stop waiting on the timeout if we got at least one machine.
    CLOUD_MACHINES_TIMEOUT: 0  # Wait indefinitely for the machines.
    CLEAN_MACHINE_NEEDED: "true"
    INSTANCE_ROLE: "XSOAR SAAS"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_SOURCE_BUCKET: "${GCS_PRODUCTION_XSOAR_SAAS_BUCKET}"
    GCS_MACHINES_BUCKET: "marketplace-saas-dist-dev/upload-flow/builds-xsoar-ng"
    NON_REMOVABLE_PACKS: "Base"
    MARKETPLACE_NAME: "xsoar_saas"
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_XSOAR}/instance_saas"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately

upload-packs-to-marketplace:
  tags:
    - $BUILD_JOB_TAG
  needs:
    - install-packs-in-server6_11
    - install-packs-in-server6_12
    - install-packs-in-server-master
    - run-pre-commit-upload-flow
    - run-validations-upload-flow
  stage: upload-to-marketplace
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    INSTANCE_ROLE: "Server Master"
    MARKETPLACE_VERSION: "xsoar"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.ssh-config-setup]
    - !reference [.check_user_permissions]
    - *upload_packs_to_the_marketplace
    - *upload_failed_to_upload_packs
    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gsutil -m -q cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - *upload_packs_results_upload
    - job-done

upload-packs-to-marketplace-v2:
  tags:
    - $BUILD_JOB_TAG
  needs: ["run-pre-commit-upload-flow", "mpv2-prepare-testing-bucket-upload-flow", "install-packs-in-xsiam-ga", "run-validations-upload-flow"]
  stage: upload-to-marketplace
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "marketplacev2"
    INSTANCE_ROLE: "XSIAM"
    PRODUCT_TYPE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.check_user_permissions]
    - *upload_packs_to_the_marketplace_v2
    - *upload_failed_to_upload_packs
    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_V2_BUCKET != $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_V2_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gsutil -m -q cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - *upload_packs_results_upload
    - job-done

upload-packs-to-xpanse-marketplace:
  tags:
    - $BUILD_JOB_TAG
  needs: ["run-pre-commit-upload-flow", "xpanse-prepare-testing-bucket-upload-flow", "run-validations-upload-flow"] # "install-packs-in-xpanse-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xpanse"
    INSTANCE_ROLE: "XPANSE"
    PRODUCT_TYPE: "XPANSE"
    SERVER_TYPE: "XPANSE"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XPANSE}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.check_user_permissions]
    - *upload_packs_to_the_marketplace_xpanse
    - *upload_failed_to_upload_packs
    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XPANSE_BUCKET != $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_XPANSE_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gsutil -m -q cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - *upload_packs_results_upload
    - job-done

upload-packs-to-xsoar-saas-marketplace:
  tags:
    - $BUILD_JOB_TAG
  needs: ["run-pre-commit-upload-flow", "xsoar-saas-prepare-testing-bucket-upload-flow", "run-validations-upload-flow", "install-packs-in-xsoar-ng-ga"]
  stage: upload-to-marketplace
  artifacts:
    expire_in: 30 days
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xsoar_saas"
    INSTANCE_ROLE: "xsoar_saas"
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""  # set to no TTL, shutdown immediately
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.check_user_permissions]
    - *upload_packs_to_the_marketplace_xsoar_saas
    - *upload_failed_to_upload_packs
    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET == $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET != $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_XSOAR_SAAS_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gsutil -m -q cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - *upload_packs_results_upload
    - job-done


upload-content-graph-data-to-bigquery:
  stage: upload-content-graph-data-to-bigquery
  needs: ["upload-packs-to-marketplace", "upload-packs-to-marketplace-v2", "upload-packs-to-xpanse-marketplace", "upload-packs-to-xsoar-saas-marketplace"]
  tags:
    - cortex-content-1738
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  variables:
    XSOAR_CONTENT_BUILD_PROJECT: "xdr-xsoar-content-dev-01"
    MP_ANALYTICS_DATASET_ID: "marketplace_analytics"
    CONTENT_ITEMS_METADATA_TABLE_ID: "content_items_data"
  script:
    - section_start "Load graph from artifacts"
    - demisto-sdk graph update -i "${ARTIFACTS_FOLDER}/content_graph/xsoar.zip"
    - section_end "Load graph from artifacts"

    - section_start "Upload data from content graph to bigquery"
    - poetry run python3 -u  "${CI_PROJECT_DIR}/Tests/Marketplace/upload_marketplace_data_to_bigquery.py"
    - section_end "Upload data from content graph to bigquery"

    - job-done


xsoar-force-pack-upload:
  needs: [ "xsoar-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_BUCKET
    MARKETPLACE: "xsoar"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_BUCKET
    GCS_BUILD_BUCKET: "marketplace-ci-build-xsoar-dev"
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

marketplace-v2-force-pack-upload:
  needs: [ "mpv2-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_V2_BUCKET
    MARKETPLACE: "marketplacev2"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_V2_BUCKET
    GCS_BUILD_BUCKET: "marketplace-ci-build-v2-dev"
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

xpanse-force-pack-upload:
  needs: [ "xpanse-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XPANSE"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XPANSE}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_XPANSE_BUCKET
    MARKETPLACE: "xpanse"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_XPANSE_BUCKET
    GCS_BUILD_BUCKET: "marketplace-ci-build-xpanse-dev"
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

xsoar-saas-force-pack-upload:
  needs: [ "xsoar-saas-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_XSOAR_SAAS_BUCKET
    MARKETPLACE: "xsoar_saas"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_XSOAR_SAAS_BUCKET
    GCS_BUILD_BUCKET: "marketplace-ci-build-xsoar-saas-dev"
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

.force-pack-upload:
  tags:
    - $BUILD_JOB_TAG
  stage: upload-to-marketplace
  extends:
    - .default-job-settings
  script:
    - !reference [.check_user_permissions]
    - EXTRACT_FOLDER=$(mktemp -d)
    - PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
    - PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
    - CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
    - GCS_BUILD_BUCKET=${GCS_BUILD_BUCKET}
    - |
      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD == $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi

      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD != $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
       STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

    - python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e "${EXTRACT_FOLDER}" -pb "${GCS_MARKET_BUCKET_TO_UPLOAD}" -bb "${GCS_BUILD_BUCKET}" -s "${GCS_MARKET_KEY}" -n "${CI_PIPELINE_ID}" -c "${CI_COMMIT_BRANCH}" -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace "${MARKETPLACE}" --artifacts-folder-server-type "${ARTIFACTS_FOLDER_SERVER_TYPE}"


fan-in-bucket-upload:
  tags:
    - gke
  stage: fan-in
  extends:
    - .bucket-upload-rule-always
  script:
    - echo "fan in"


slack-notify-bucket-upload:
  extends:
    - .bucket-upload-rule-always
    - .trigger-slack-notification
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    JOB_NAME: 'fan-in-bucket-upload'
    WORKFLOW: 'Upload Packs to Marketplace Storage'
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_PARENT_PIPELINE_ID: $SLACK_PARENT_PIPELINE_ID
    SLACK_PARENT_PROJECT_ID: $SLACK_PARENT_PROJECT_ID
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'false'
    CI_PROJECT_ID: $CI_PROJECT_ID
    CI_SERVER_URL: $CI_SERVER_URL
    JIRA_SERVER_URL: $JIRA_SERVER_URL
    JIRA_VERIFY_SSL: $JIRA_VERIFY_SSL
    JIRA_API_KEY: $JIRA_API_KEY
    JIRA_PROJECT_ID: $JIRA_PROJECT_ID
    JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME: $JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME
    CURRENT_BRANCH_NAME: $INFRA_BRANCH

upload-id-set-bucket:
  needs:
    - cloning-repositories-upload-flow
  tags:
    - gke
  stage: prepare-testing-bucket
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    INSTANCE_ROLE: "Server Master"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER}/server_type_${SERVER_TYPE}"
  script:
    # This is needed because we still use id_set.json in other repos
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Skipping uploading id-set to the bucket in test upload-flow"
        job-done
        exit 0
      fi

    - !reference [.create-id-set-xsoar]
    - gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/id_set.json" "gs://$GCS_MARKET_BUCKET/content/id_set.json"
    - job-done

.sync-buckets-between-projects:
  # syncs buckets from oproxy-dev/oproxy-prod projects to xdr-xsoar-content-dev-01/xdr-xsoar-content-prod-us-01 projects
  tags:
    - gke
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  stage: sync-buckets
  variables:
    MARKETPLACE_XSOAR_PROD: "marketplace-xsoar"
    MARKETPLACE_V2_PROD: "marketplace-xsiam"
    MARKETPLACE_XPANSE_PROD: "marketplace-xpanse"
  script:
    - |
      if [[ "${TEST_UPLOAD}" == "true" ]] || [[ "${DRY_RUN}" == "true" ]]; then
        echo -n "skipped" >> ${ARTIFACTS_FOLDER}/logs/trigger_sync_all_buckets_status_code.log
        echo "Skipping syncing buckets in test upload-flow and test override core packs."
        job-done
        exit 0
      fi

    - |
      if [[ -z "$GCS_XSOAR_CONTENT_DEV_KEY" ]] || [[ -z "$GCS_XSOAR_CONTENT_PROD_KEY" ]]; then
        echo "GCS_XSOAR_CONTENT_DEV_KEY or GCS_XSOAR_CONTENT_PROD_KEY not set, cannot perform sync"
        job-done
        exit 1
      else
        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_DEV_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1

        echo "Syncing gs://marketplace-xsoar-dev"
        gsutil -m -q rsync -r gs://marketplace-saas-dist gs://marketplace-xsoar-dev
        echo "Syncing gs://marketplace-xsiam-dev"
        gsutil -m -q rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-dev
        echo "Syncing gs://marketplace-xpanse-dev"
        gsutil -m -q rsync -r gs://xpanse-dist gs://marketplace-xpanse-dev

        ./Tests/scripts/validate_synced_buckets.sh "dev"

        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_PROD_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1

        echo "Syncing gs://marketplace-xsoar-prod-us"
        gsutil -m -q rsync -r gs://marketplace-saas-dist gs://marketplace-xsoar-prod-us
        echo "Syncing gs://marketplace-xsiam-prod-us"
        gsutil -m -q rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-prod-us
        echo "Syncing gs://marketplace-xpanse-prod-us"
        gsutil -m -q rsync -r gs://xpanse-dist gs://marketplace-xpanse-prod-us

        ./Tests/scripts/validate_synced_buckets.sh "prod-us"

        echo "Bucket prod-us sync completed"
      fi

    # The next step triggers a pipeline by the DevOps team that synchronizes between the `prod us` bucket and all other buckets.
    # If this step fails, a message will appear in the Slack channel `dmst-build`.
    # If the step is successful, a message will appear in the thread under the upload message.
    # Note: Failure of this step indicates an issue with triggering the pipeline, not with its process.
    # For job status updates see xdr-content-sync channel.
    - section_start "Trigger sync for all buckets" --collapsed
    - poetry run python3 -u ./Tests/scripts/trigger_jenkins_job.py --url $JENKINS_SYNC_BUCKETS_JOB_URL --username $JENKINS_USER --token $JENKINS_TOKEN
    - section_end "Trigger sync for all buckets"
    - job-done


sync-buckets-between-projects:
  extends: .sync-buckets-between-projects
  needs:
    - job: upload-packs-to-marketplace
      artifacts: false
    - job: upload-packs-to-marketplace-v2
      artifacts: false
    - job: upload-packs-to-xpanse-marketplace
      artifacts: false
    - job: upload-packs-to-xsoar-saas-marketplace
      artifacts: false
    - job: mpv2-prepare-testing-bucket-upload-flow
      artifacts: false
    - job: xpanse-prepare-testing-bucket-upload-flow
      artifacts: false
    - job: xsoar-prepare-testing-bucket-upload-flow
      artifacts: false
    - job: xsoar-saas-prepare-testing-bucket-upload-flow
      artifacts: false
    - job: cloning-repositories-upload-flow
      artifacts: true

force-upload-sync-buckets-between-projects:
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'
  extends: .sync-buckets-between-projects
  needs: ["xsoar-force-pack-upload", "marketplace-v2-force-pack-upload", "xpanse-force-pack-upload", "xsoar-saas-force-pack-upload"]
