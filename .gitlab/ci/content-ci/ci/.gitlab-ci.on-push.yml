# This rule is to not run the build for docker update branches (for non-nightly packs)
.filter-non-nightly-docker-updates-rule:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /^demisto\// && $CI_COMMIT_BRANCH !~ /^demisto\/.*-nightly$/'
      when: never

.push-rule:
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'

.create-release-notes-and-common-docs:
  - section_start "Create Release Notes and Common Server Documentation" --collapsed
  - echo "Creating Release Notes and Content Descriptor"
  - poetry install --with documentation
  - ./Documentation/commonServerDocs.sh
  - section_end "Create Release Notes and Common Server Documentation"

merge-dev-secrets:
  tags:
    - gke
  extends:
    - .default-job-settings
  variables:
    master_branch_name: master
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH == $master_branch_name'
  stage: unittests-and-validations
  script:
    - EXIT_CODE=0
    - section_start "Merging and deleting dev secrets"
    - python3 ./SecretActions/SecretsBuild/merge_and_delete_dev_secrets.py -sa "$GSM_SERVICE_ACCOUNT" --gsm_project_id_dev "$GSM_PROJECT_ID_DEV" --gsm_project_id_prod "$GSM_PROJECT_ID" >> "${ARTIFACTS_FOLDER}/logs/merge_secrets.log" 2>&1 || EXIT_CODE=$?
    - job-done
    - exit $EXIT_CODE
    - section_end "Merging and deleting dev secrets"
  allow_failure: true

cloning-repositories:
  stage: .pre
  rules:
    - if: '$IS_NIGHTLY == "true"'
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NATIVE_NIGHTLY == "true"'
  extends:
    - .cloning-repositories
  script:
    - !reference [.check_build_files_are_up_to_date]
    - !reference [.add-content-production-to-artifacts]
    - job-done

stop-running-pipelines:
  tags:
    - gke
  stage: unittests-and-validations
  extends:
    - .default-job-settings
  variables:
    master_branch_name: master
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH != $master_branch_name'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  needs:
    - cloning-repositories
  script:
    - section_start "Stop running pipelines on current branch"
    - python3 ./Tests/scripts/stop_running_pipeline.py --creds "${CONTENT_BUILD_GCP}" --zone "${GCP_ZONE}"
    - section_end "Stop running pipelines on current branch"
    - job-done

run-pre-commit:
  extends:
    - .run-pre-commit
  needs:
    - cloning-repositories
  rules:
    - if: '$IS_NIGHTLY == "true"'
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  cache:
    policy: pull-push
  parallel:
    matrix:
      - PRE_COMMIT_DOCKER_IMAGE:
          - "from-yml"

# runs in gitlab for the on-push flow (except for contributors)
run-validations:
  needs:
    - cloning-repositories
  extends:
    - .run-validations
  rules:
    - if: '$IS_NIGHTLY == "true"'
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'

# runs in gitlab for the on-push flow (except for contributors)
run-validations-new-validate-flow:
  needs:
    - cloning-repositories
  extends:
    - .run-validations-new-validate-flow
  rules:
    - if: '$IS_NIGHTLY == "true"'
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'


# runs in gitlab for the on-push flow, on every new commit pushed to the branch.
validate-content-conf:
  needs:
      - cloning-repositories
  tags:
    - gke
  stage: unittests-and-validations
  extends:
    - .default-job-settings
  rules:
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  script:
    - !reference [ .validate_content_test_conf_branch_merged ]
    - job-done


.check_bypass_url_label: &check_bypass_url_label
  - section_start "Check if bypass.url Label in the PR"
  - |
    pr=$(curl -sS --get --header "Accept: application/vnd.github.v3.raw" --header "Authorization: token $GITHUB_TOKEN" "https://api.github.com/repos/demisto/content/pulls?state=open&base=master" --data-urlencode "head=demisto:${CI_COMMIT_BRANCH}" | jq '.[0]')
    EXIT_CODE=$?
    if [[ "${EXIT_CODE}" -ne 0 ]]; then
      echo "Failed to fetch PR details, exit code:${EXIT_CODE}"
      exit "${EXIT_CODE}"
    fi

    has_label=false
    if [[ $pr != 'null' ]]; then
      pr_number=$(echo $pr | jq -r '.number')
      pr_labels=$(curl -sS --get --header "Accept: application/vnd.github.v3.raw" --header "Authorization: token $GITHUB_TOKEN" "https://api.github.com/repos/demisto/content/issues/${pr_number}/labels" | jq '.[].name')
      EXIT_CODE=$?
      if [[ "${EXIT_CODE}" -ne 0 ]]; then
        echo "Failed to fetch PR details, exit code:${EXIT_CODE}"
        exit "${EXIT_CODE}"
      fi


      if echo "$pr_labels" | grep -q "bypass.url"; then
        has_label=true
        echo "The PR has the bypass.url label."
      fi
    fi
  - section_end "Check if bypass.url Label in the PR"

.generic-prepare-testing-bucket:
  tags:
    - gce
    - cortex-content-1738  # The tag is bound to an identifier that grants access to Google resources such as marketplace-ci-build-...-dev buckets etc.
  extends:
    - .default-job-settings
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: "$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/"
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NATIVE_NIGHTLY == "true"'
    - if: '$IS_NIGHTLY == "true"'
      variables:
        IFRA_ENV_TYPE: "Nightly"
  cache:
    policy: pull-push
  variables:
    EXTRACT_PRIVATE_TESTDATA: "true"
    KUBERNETES_MEMORY_REQUEST: 16Gi
    KUBERNETES_MEMORY_LIMIT: 16Gi
  stage: prepare-testing-bucket
  script:
    - !reference [.create-release-notes-and-common-docs]

    - section_start "Create or update content graph" --collapsed
    - gcloud auth configure-docker --quiet ${DOCKER_IO_DOMAIN} >> "${ARTIFACTS_FOLDER}/logs/configure_docker_with_registry.log" 2>&1
    - |
        echo "set DEMISTO_SDK_GRAPH_FORCE_CREATE to true to create graph from scratch"
        export DEMISTO_SDK_GRAPH_FORCE_CREATE=true
        echo "DEMISTO_SDK_GRAPH_FORCE_CREATE was set to true to create graph from scratch"
        echo $DEMISTO_SDK_GRAPH_FORCE_CREATE
    - echo "Staging the repo to include the private packs in the graph"
    - git add Packs
    - echo "Updating the content graph"
    - mkdir "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_graph"
    - demisto-sdk graph update -g --marketplace "${MARKETPLACE_VERSION}" --output-path "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_graph"
    - echo "Successfully updated content graph"

    - section_end "Create or update content graph"

    - section_start "Create Content Artifacts and Update Conf" --collapsed
    - export DEMISTO_SDK_MARKETPLACE=$MARKETPLACE_VERSION  # This is done because the demisto-sdk uses this environment variable.
    - |
      if [[ $MARKETPLACE_VERSION == "xsoar" || $MARKETPLACE_VERSION == "xsoar_saas" ]];  # later the non xsoar will be edited to remove xsoar naming.
      then
        echo "Starting to create artifacts with zip for XSOAR."
        python Tests/scripts/create_artifacts_graph/create_artifacts.py --marketplace "$MARKETPLACE_VERSION" --artifacts-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs" --dependencies-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json" --packs-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs.json" --bucket-upload "${BUCKET_UPLOAD}"
      else
        echo "Starting to create artifacts without zip."
        python Tests/scripts/create_artifacts_graph/create_artifacts.py --marketplace "$MARKETPLACE_VERSION" --artifacts-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs" --dependencies-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json" --packs-output "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs.json" --bucket-upload "${BUCKET_UPLOAD}" --no-zip
      fi

    - section_end "Create Content Artifacts and Update Conf"

    - section_start "Copy conf.json To Server Type Artifacts Folder"
    - cp "./Tests/conf.json" "${ARTIFACTS_FOLDER_SERVER_TYPE}/conf.json"
    - section_end "Copy conf.json To Server Type Artifacts Folder"

    - section_start "Find dependencies changes" --collapsed
    - |
      if [[ "${BUCKET_UPLOAD}" == "false" ]] || [[ "${TEST_UPLOAD}" == "false" ]]; then
        source ./Tests/scripts/get_previous_master_sha.sh
        if [[ -z $PREVIOUS_MASTER_SHA ]]; then
          echo "WARNING: failed to detect previous master SHA, skipping find dependencies changes"
        else
          echo "Finding pack dependencies diff against $PREVIOUS_MASTER_SHA"
          python Tests/scripts/find_pack_dependencies_changes.py --gitlab-token $GITLAB_API_TOKEN --master-sha $PREVIOUS_MASTER_SHA --job-name $CI_JOB_NAME --artifacts-folder "$ARTIFACTS_FOLDER_SERVER_TYPE"
        fi
      else
        echo "Test upload flow - skipping find dependencies changes"
      fi
    - section_end "Find dependencies changes"
    - section_start "Zip Xspanse and Xsiam" --collapsed
    - |
      if [[ $MARKETPLACE_VERSION == "marketplacev2" ||  $MARKETPLACE_VERSION == "xpanse" ]];
      then
        pushd "${ARTIFACTS_FOLDER_SERVER_TYPE}"
        pushd content_packs; zip -r ../content_packs.zip * 1> /dev/null; popd
        rm -rf content_packs
        popd
      fi
    - section_end "Zip Xspanse and Xsiam"
    - section_start "Collect Tests" --collapsed
    - |
      if [ -n "${INSTANCE_TESTS}" ]; then
        echo "Skipping - not running in INSTANCE_TESTS build"
      else
        python3 ./Tests/scripts/collect_tests/collect_tests.py -n "${IS_NIGHTLY}" --native-nightly "${IS_NATIVE_NIGHTLY}" --sdk-nightly "${DEMISTO_SDK_NIGHTLY}" --marketplace "$MARKETPLACE_VERSION" --service_account $GCS_MARKET_KEY --graph true --override_all_packs $OVERRIDE_ALL_PACKS -up "${PACKS_TO_UPLOAD}"
      fi
    - section_end "Collect Tests"

    - *check_bypass_url_label
    - |
      if [[ "${BUCKET_UPLOAD}" == "true" || "${IS_NIGHTLY}" == "true" ||
      -s "${ARTIFACTS_FOLDER_SERVER_TYPE}/modeling_rules_to_test.json" ||
      -s "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_file.txt" || "${has_label}" == "true" ]]; then

        section_start "Prepare Content Packs for Testing" --collapsed
        ./Tests/scripts/prepare_content_packs_for_testing.sh "$MARKETPLACE_BUCKET" "$STORAGE_BASE_PATH" "$MARKETPLACE_VERSION"
        section_end "Prepare Content Packs for Testing"

        section_start "Override and upload core packs versions" --collapsed
        ./Tests/Marketplace/upload_versions_core_files.sh "$MARKETPLACE_BUCKET" "$STORAGE_BASE_PATH" "$MARKETPLACE_VERSION" "$LAST_UPLOAD_COMMIT"
        section_end "Override and upload core packs versions"

        section_start "Validate core packs list versions" --collapsed
        python3 ./Tests/Marketplace/validate_core_packs_list_versions.py -s "${GCS_MARKET_KEY}" -c "${CI_COMMIT_REF_NAME}" -mp "${MARKETPLACE_VERSION}" -bb "${GCS_BUILD_BUCKET}" -n "${CI_PIPELINE_ID}"
        section_end "Validate core packs list versions"

      else
        echo "Skipping - Prepare Content Packs for Testing, Override and upload core packs versions, Validate core packs list versions."
      fi

    - section_start "Create Instances for XSOAR"
    - |
      if [[ ${MARKETPLACE_VERSION} = "xsoar" ]]; then
        echo "Creating Instances, only for XSOAR."
        if [[ "${DEMISTO_SDK_NIGHTLY}" == "true" ]]; then
          echo "Creating Xsoar Instances for SDK nightly- changing the filter_envs json."
          jq '.' <<< '{"Server 6.11": false, "Server 6.12": false, "Server Master": true}' > "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_envs.json"
        fi
        if [[ "${IS_NATIVE_NIGHTLY}" == "true" ]]; then
          echo "Creating Xsoar Instances for Native nightly- changing the filter_envs json."
          jq '.' <<< '{"Server 6.11": false, "Server 6.12": false, "Server Master": false}' > "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_envs.json"
        fi
        python3 ./gcp/create_instance.py --env-type "${IFRA_ENV_TYPE}" --outfile "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json" --filter-envs "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_envs.json" --creds "${CONTENT_BUILD_GCP}" --zone "${GCP_ZONE}" --instances-config "${CI_PROJECT_DIR}/config/instances_config.json"
      fi
    - section_end "Create Instances for XSOAR"
    - section_start "Upload Artifacts to GCP" --collapsed
    - ./Tests/scripts/upload_artifacts.sh
    - section_end "Upload Artifacts to GCP"
    - echo "create instances done" > "${ARTIFACTS_FOLDER_SERVER_TYPE}/create_instances_done.txt"
    - job-done

xsoar-prepare-testing-bucket:
  tags:
    - cortex-content-1738
  needs:
    - cloning-repositories
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    MARKETPLACE_VERSION: "xsoar"
    MARKETPLACE_BUCKET: "$GCS_MARKET_BUCKET"
  extends:
    - .generic-prepare-testing-bucket
    - .docker_services

xsoar-saas-prepare-testing-bucket:
  tags:
    - cortex-content-1738
  needs:
    - cloning-repositories
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    MARKETPLACE_VERSION: "xsoar_saas"
    MARKETPLACE_BUCKET: "$GCS_MARKET_XSOAR_SAAS_BUCKET"
    GCS_BUILD_BUCKET: "$GCS_BUILD_XSOAR_SAAS_BUCKET"
  extends:
    - .generic-prepare-testing-bucket
    - .docker_services
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: "$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/"
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true"'
      variables:
        IFRA_ENV_TYPE: "Nightly"
    - if: '$IS_NATIVE_NIGHTLY == "true"'


mpv2-prepare-testing-bucket:
  tags:
    - cortex-content-1738
  needs:
    - cloning-repositories
  variables:
    PRODUCT_TYPE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    MARKETPLACE_VERSION: "marketplacev2"
    MARKETPLACE_BUCKET: "$GCS_MARKET_V2_BUCKET"
    GCS_BUILD_BUCKET: "$GCS_BUILD_V2_BUCKET"
    PRODUCT_NAME: "Cortex XSIAM"
  extends:
    - .generic-prepare-testing-bucket
    - .docker_services

xpanse-prepare-testing-bucket:
  tags:
    - cortex-content-1738
  needs:
    - cloning-repositories
  variables:
    PRODUCT_TYPE: "XPANSE"
    SERVER_TYPE: "XPANSE"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XPANSE}/server_type_${SERVER_TYPE}"
    MARKETPLACE_VERSION: "xpanse"
    PRODUCT_NAME: "Cortex XPANSE"
    MARKETPLACE_BUCKET: "$GCS_MARKET_XPANSE_BUCKET"
    GCS_BUILD_BUCKET: "$GCS_BUILD_XPANSE_BUCKET"
  extends:
    - .generic-prepare-testing-bucket
    - .docker_services

.run_tests:
  - section_start "Run Tests"
  # - |
  #   if [[ "${IS_NIGHTLY}" == "true" && "${SERVER_TYPE}" == "XSIAM" ]]; then
  #     ./Tests/scripts/run_e2e_tests.sh || EXIT_CODE=$?
  #   fi
  - |
    if [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/conf.json" ]]; then
      cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/conf.json" Tests/conf.json
    fi
  - ./Tests/scripts/run_tests.sh || EXIT_CODE=$?
  - rm -f Tests/conf.json
  - section_end "Run Tests"

.test_content_on_xsoar_server_instances_base:
  tags:
    - $BUILD_JOB_TAG
  extends:
    - .default-job-settings
    - .push-rule
  variables:
    SERVER_TYPE: "XSOAR"
    PRODUCT_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}/"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_XSOAR}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    MARKETPLACE_NAME: "xsoar"
  stage: run-instances
  needs:
    - job: xsoar-prepare-testing-bucket
  script:
    - EXIT_CODE=0
    - section_start "Check if should run Instance role"
    - export INSTANCES_CREATED_FOR_ROLE=$(cat "${ENV_RESULTS_PATH}" | jq -c "map(select(.Role == \"${INSTANCE_ROLE}\")) | length")
    - |
      echo "Instance role:${INSTANCE_ROLE} Product type:${PRODUCT_TYPE} Instances created for role:${INSTANCES_CREATED_FOR_ROLE}"
      if [[ "${INSTANCES_CREATED_FOR_ROLE}" -eq 0 ]]; then
        echo "Instances with role ${INSTANCE_ROLE} were not created, not running the instance flow."
        rm -f "${ARTIFACTS_FOLDER_INSTANCE}/instance_role.txt" # delete the instance_role.txt file so the job will not be collected by slack notifier.
        job-done
        exit 0
      fi
    - section_end "Check if should run Instance role"

    # job secrets-fetch will be removed when test-content will be moved to infra in ./Tests/scripts/run_tests.sh
    - !reference [.secrets-fetch]

    - !reference [.ssh-config-setup]

    - section_start "Wait Until Server Ready"
    - python3 ./Tests/scripts/wait_until_server_ready.py  -n "${IS_NIGHTLY}" --instance-role "${INSTANCE_ROLE}"
    - section_end "Wait Until Server Ready"
    - section_start "Copy env results to artifacts folder" --collapsed
    - |
      # workaround for the hard-coded value in the sdk
      cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json" "./artifacts/env_results.json"
      cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_file.txt" "./artifacts/filter_file.txt"
    - section_end "Copy env results to artifacts folder"
    - !reference [.install_packs_by_machines]
    - section_start "Avoid running playbooks on nightly" --collapsed
    - |
      if [[ "${IS_NIGHTLY}" == "true" ]]; then
        echo "IS_NIGHTLY is set to true. Skipping run tests."
        ./Tests/scripts/run_tests.sh --generate-empty-result-file
        # workaround for the hard-coded value in the sdk
        rm -f "./artifacts/env_results.json"
        rm -f "./artifacts/filter_file.txt"
        job-done
        exit $EXIT_CODE
      fi
    - section_end "Avoid running playbooks on nightly"
    - section_start "Wait Until Server Ready"
    - echo Going to sleep for 15 minutes to allow server finish indexing
    - sleep-with-progress 900 30 "Sleeping... " 150
    - echo "Done sleeping!"
    - section_end "Wait Until Server Ready"
    - !reference [.run_tests]
    - section_start "Get instance ssh-command"
    - echo "INSTANCE_ROLE -> ${INSTANCE_ROLE}"
    - INSTANCE_NAME=$(jq -r --arg role "$INSTANCE_ROLE" '.[] | select(.Role == $role) | .InstanceName' ./artifacts/env_results.json)
    - echo -e "\e[1m gcloud compute ssh --zone \"us-central1-a\" \"${INSTANCE_NAME}\"  --tunnel-through-iap --project "xsoar-content-build" \e[0m"
    - section_end "Get instance ssh-command"
    - section_start "Cleanup env results from artifacts folder" --collapsed
    - |
      # workaround for the hard-coded value in the sdk
      rm -f "./artifacts/env_results.json"
      rm -f "./artifacts/filter_file.txt"
    - section_end "Cleanup env results from artifacts folder"
    - job-done
    - exit $EXIT_CODE
  after_script:
    - !reference [.default-after-script]
    - !reference [.install_ssh_keys]
    - !reference [.ssh-config-setup]
    - !reference [.destroy_xsoar_instances]
  artifacts:
    when: always
    expire_in: 30 days
    reports:
      junit:
        - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
    paths:
      - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
      - ${CI_PROJECT_DIR}/artifacts/*  # restoring the default artifacts path from the job default settings
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*  # restoring the default artifacts path from the job default settings

tests_xsoar_server:
  extends:
    - .test_content_on_xsoar_server_instances_base
  #  No need to trigger in case of release branch or docker update branches (non-nightly packs)
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true"'
    - if: '$IS_NATIVE_NIGHTLY == "true"'
  parallel:
    matrix:
      - INSTANCE_ROLE:
        - "Server 6.11"
        - "Server 6.12"
        - "Server Master"

fan-in-nightly:
  tags:
    - gke
  stage: fan-in
  rules:
    - if: '$IS_NIGHTLY == "true"'
      when: always
  script:
    - echo "fan in nightly"

fan-in-native-nightly:
  tags:
    - gke
  stage: fan-in
  rules:
    - if: '$IS_NATIVE_NIGHTLY == "true"'
      when: always
  script:
    - echo "fan in native nightly"

jobs-done-check-nightly:
  extends:
    - .jobs-done-check
  needs:
    - cloning-repositories
    - run-pre-commit
    - run-validations
    - run-validations-new-validate-flow
    - mpv2-prepare-testing-bucket
    - xpanse-prepare-testing-bucket
    - xsoar-prepare-testing-bucket
    - xsoar-saas-prepare-testing-bucket
    - xsiam_server_ga
    - xsoar_ng_server_ga
    - tests_xsoar_server
    - xsoar-test_playbooks_results
    - xsiam-test_playbooks_results
    - xsiam-test_modeling_rule_results
  tags:
    - gke
  rules:
    - if: '$IS_NIGHTLY == "true"'
      when: always
  variables:
    WORKFLOW: 'Content Nightly'

fan-in-on-push:
  when: always
  stage: fan-in
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH != $master_branch_name'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  tags:
    - gke
  script:
    - echo "fan in on push"
  variables:
    master_branch_name: master

jobs-done-check-on-push:
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH != $master_branch_name'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  extends:
    - .push-rule
    - .jobs-done-check
  needs:
    - cloning-repositories
    - run-pre-commit
    - run-validations
    - run-validations-new-validate-flow
    - stop-running-pipelines
    - test-upload-flow
    - validate-content-conf
    - mpv2-prepare-testing-bucket
    - xpanse-prepare-testing-bucket
    - xsoar-prepare-testing-bucket
    - xsoar-saas-prepare-testing-bucket
    - xsiam_server_ga
    - tests_xsoar_server
    - xsoar_ng_server_ga
    - xsoar-test_playbooks_results
    - xsiam-test_playbooks_results
    - xsiam-test_modeling_rule_results
  tags:
    - gke
  variables:
    WORKFLOW: 'Content PR'
    master_branch_name: master

fan-in-on-merge:
  when: always
  stage: fan-in
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH == $master_branch_name'
  tags:
    - gke
  script:
    - echo "fan in on merge"
  variables:
    master_branch_name: master

jobs-done-check-on-merge:
  rules:
    - !reference [ .filter-non-nightly-docker-updates-rule, rules ]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH == $master_branch_name'
  extends:
    - .push-rule
    - .jobs-done-check
  needs:
    - cloning-repositories
    - merge-dev-secrets
    - run-pre-commit
    - run-validations
    - run-validations-new-validate-flow
    - test-upload-flow
    - validate-content-conf
    - mpv2-prepare-testing-bucket
    - xpanse-prepare-testing-bucket
    - xsoar-prepare-testing-bucket
    - xsoar-saas-prepare-testing-bucket
    - xsiam_server_ga
    - tests_xsoar_server
    - xsoar_ng_server_ga
    - xsoar-test_playbooks_results
    - xsiam-test_playbooks_results
    - xsiam-test_modeling_rule_results
  tags:
    - gke
  variables:
    WORKFLOW: 'Content Merge'
    master_branch_name: master

slack-notify-nightly-build:
  rules:
    - if: '$IS_NIGHTLY == "true"'
      when: always
  extends:
    - .trigger-slack-notification
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    JOB_NAME: 'fan-in-nightly'
    WORKFLOW: 'Content Nightly'
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_PARENT_PIPELINE_ID: $SLACK_PARENT_PIPELINE_ID
    SLACK_PARENT_PROJECT_ID: $SLACK_PARENT_PROJECT_ID
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'false'
    CI_PROJECT_ID: $CI_PROJECT_ID
    CI_SERVER_URL: $CI_SERVER_URL
    JIRA_SERVER_URL: $JIRA_SERVER_URL
    JIRA_VERIFY_SSL: $JIRA_VERIFY_SSL
    JIRA_API_KEY: $JIRA_API_KEY
    JIRA_PROJECT_ID: $JIRA_PROJECT_ID
    JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME: $JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME
    CURRENT_BRANCH_NAME: $INFRA_BRANCH

slack-notify-on-push:
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH != $master_branch_name'
      when: always
    - if: '$TRIGGER_TEST_BRANCH == "true"'
      when: always
  extends:
    - .trigger-slack-notification
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    JOB_NAME: 'fan-in-on-push'
    WORKFLOW: 'Content PR'
    master_branch_name: master
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_PARENT_PIPELINE_ID: $SLACK_PARENT_PIPELINE_ID
    SLACK_PARENT_PROJECT_ID: $SLACK_PARENT_PROJECT_ID
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'true'
    CI_PROJECT_ID: $CI_PROJECT_ID
    CI_SERVER_URL: $CI_SERVER_URL
    JIRA_SERVER_URL: $JIRA_SERVER_URL
    JIRA_VERIFY_SSL: $JIRA_VERIFY_SSL
    JIRA_API_KEY: $JIRA_API_KEY
    JIRA_PROJECT_ID: $JIRA_PROJECT_ID
    JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME: $JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME
    CURRENT_BRANCH_NAME: $INFRA_BRANCH

slack-notify-on-merge:
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/ && $CI_COMMIT_BRANCH == $master_branch_name'
      when: always
  extends:
    - .trigger-slack-notification
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    JOB_NAME: 'fan-in-on-merge'
    WORKFLOW: 'Content Merge'
    master_branch_name: master
    SLACK_CHANNEL: "dmst-build-test"
    SLACK_PARENT_PIPELINE_ID: $SLACK_PARENT_PIPELINE_ID
    SLACK_PARENT_PROJECT_ID: $SLACK_PARENT_PROJECT_ID
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'false'
    CURRENT_BRANCH_NAME: $INFRA_BRANCH

.test_content_on_cloud_server_instances_base:
  tags:
    - $BUILD_JOB_TAG
  extends:
    - .default-job-settings
    - .push-rule
  variables:
    EXTRACT_PRIVATE_TESTDATA: "true"
    KUBERNETES_MEMORY_REQUEST: 8Gi
    KUBERNETES_MEMORY_LIMIT: 16Gi
  stage: run-instances
  script:
    - EXIT_CODE=0

    # job secrets-fetch will be removed when test-content will be moved to infra in ./Tests/scripts/run_tests.sh
    - !reference [.secrets-fetch]

    - section_start "Are there tests to run?" --collapsed
    - |
      if ! [[ -s "${ARTIFACTS_FOLDER_SERVER_TYPE}/modeling_rules_to_test.json" || -s "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_file.txt" ]]; then
        # The files are empty.
        echo "Not running the instance flow, no tests to run were found."
        ./Tests/scripts/run_tests.sh --generate-empty-result-file
        ./Tests/scripts/test_modeling_rules.sh --generate-empty-result-file
        job-done
        exit $EXIT_CODE
      fi
    # workaround for the hard-coded value in the sdk
    - cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/filter_file.txt" "./artifacts/filter_file.txt"
    - section_end "Are there tests to run?"

    - !reference [.update-content-graph]
    - !reference [.lock-machine]
    - !reference [.uninstall-packs-and-reset-bucket-cloud]
    - !reference [.install_packs_by_machines]
    - !reference [.run_tests]
    - section_start "Test Modeling Rules"
    - ./Tests/scripts/test_modeling_rules.sh || EXIT_CODE=$?
    - section_end "Test Modeling Rules"

    - section_start "Packs re-installation test"
    - |
      if [[ "${IS_NIGHTLY}" == "false" && -s "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_reinstall_to_test.txt" ]]; then
        echo "Running the packs re-installation test."
        ./Tests/scripts/reinstall_packs_on_cloud_instances.sh || EXIT_CODE=$?
      fi
    - section_end "Packs re-installation test"

    - !reference [.cloud-machine-information]
    - section_start "Cleanup env results from artifacts folder" --collapsed
    - |
      # workaround for the hard-coded value in the sdk
      rm -f "./artifacts/filter_file.txt"
    - section_end "Cleanup env results from artifacts folder"

    - job-done
    - exit $EXIT_CODE
  after_script:
    - source .gitlab/helper_functions.sh
    - !reference [.clean-machine]
    - !reference [.unlock-machine]

xsiam_server_ga:
  extends:
    - .test_content_on_cloud_server_instances_base
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true" && $SCHEDULED_NIGHTLY == "false"'
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "nightly"
        CLEAN_MACHINE_NEEDED: "true"
        CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">0" # don't run the job if there are no machines available.
        CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">0" # stop waiting on the timeout if we got at least one machine.
        CLOUD_MACHINES_TIMEOUT: 0  # Wait indefinitely for the machines.
        GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga-nightly"
    - if: '$IS_NIGHTLY == "true" && $SCHEDULED_NIGHTLY == "true"'  # On scheduled nightly, we want to run more machines.
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "nightly"
        CLEAN_MACHINE_NEEDED: "true"
        CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">=2" # don't run the job if there are less than 2 machines available.
        CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">=50%" # stop waiting on the timeout if we got 50% of the machines.
        CLOUD_MACHINES_TIMEOUT: 1200  # 20 minutes
        GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga-nightly"
  timeout: 12 hours
  variables:
    CLOUD_MACHINES_TYPE: "build"
    CLEAN_MACHINE_NEEDED: "true"
    CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">0" # don't run the job if there are no machines available.
    CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">0" # stop waiting on the timeout if we got at least one machine.
    CLOUD_MACHINES_TIMEOUT: 0  # Wait indefinitely for the machines.
    INSTANCE_ROLE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    PRODUCT_TYPE: "XSIAM"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_MPV2}/instance_xsiam"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    GCS_MARKET_BUCKET: "${GCS_MARKET_V2_BUCKET}"
    GCS_SOURCE_BUCKET: "$GCS_PRODUCTION_V2_BUCKET"
    GCS_MACHINES_BUCKET: "marketplace-v2-dist-dev/upload-flow/builds-xsiam"
    MARKETPLACE_NAME: "marketplacev2"
    NON_REMOVABLE_PACKS: "Base"
  needs:
    - job: mpv2-prepare-testing-bucket
      optional: true
  artifacts:
    when: always
    expire_in: 30 days
    reports:
      junit:
        - "${ARTIFACTS_FOLDER_INSTANCE}/test_modeling_rules_report.xml"
        - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
    paths:
      - "${ARTIFACTS_FOLDER_INSTANCE}/test_modeling_rules_report.xml"
      - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
      - ${CI_PROJECT_DIR}/artifacts/*  # restoring the default artifacts path from the job default settings
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*  # restoring the default artifacts path from the job default settings

xsoar_ng_server_ga:
  extends:
    - .test_content_on_cloud_server_instances_base
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true" && $SCHEDULED_NIGHTLY == "true"'
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "nightly"
        CLEAN_MACHINE_NEEDED: "true"
        CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">=3" # don't run the job if there are less than 3 machines available.
        CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">=50%" # stop waiting on the timeout if we got 50% of the machines.
        CLOUD_MACHINES_TIMEOUT: 1200 # 20 minutes
        GCS_LOCKS_PATH: "content-locks/locks-xsoar-ng-nightly"
    - if: '$IS_NATIVE_NIGHTLY == "true"'
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "native-nightly"
        CLEAN_MACHINE_NEEDED: "true"
        CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">1" # don't run the job if there are less than 1 machines available.
        CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">=100%" # stop waiting on the timeout if we got 100% of the machines.
        CLOUD_MACHINES_TIMEOUT: 1200  # 20 minutes
        GCS_LOCKS_PATH: "content-locks/locks-xsoar-ng-native-nightly"
    - if: '$IS_NIGHTLY == "true"'
  variables:
    CLEAN_MACHINE_NEEDED: "true"
    CLOUD_MACHINES_TYPE: "build"
    CLOUD_MACHINES_COUNT_MINIMUM_CONDITION: ">0" # don't run the job if there are no machines available.
    CLOUD_MACHINES_COUNT_TIMEOUT_CONDITION: ">0" # stop waiting on the timeout if we got at least one machine.
    CLOUD_MACHINES_TIMEOUT: 0  # Wait indefinitely for the machines.
    INSTANCE_ROLE: "XSOAR SAAS"
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR SAAS"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_LOCKS_PATH: "content-locks/locks-xsoar-ng"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_XSOAR}/instance_saas"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    GCS_SOURCE_BUCKET: "${GCS_PRODUCTION_XSOAR_SAAS_BUCKET}"
    GCS_MACHINES_BUCKET: "marketplace-saas-dist-dev/upload-flow/builds-xsoar-ng"
    MARKETPLACE_NAME: "xsoar_saas"
    NON_REMOVABLE_PACKS: "Base"
  needs:
    - job: xsoar-saas-prepare-testing-bucket
  artifacts:
    when: always
    expire_in: 30 days
    reports:
      junit:
        - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
    paths:
      - "${ARTIFACTS_FOLDER_INSTANCE}/test_playbooks_report.xml"
      - ${CI_PROJECT_DIR}/artifacts/*  # restoring the default artifacts path from the job default settings
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*  # restoring the default artifacts path from the job default settings

test-upload-flow:
  needs:
    - cloning-repositories
  tags:
    - gke
  extends:
    - .default-job-settings
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
  variables:
    ALL_BUCKETS: "$GCS_MARKET_BUCKET_DEV,$GCS_MARKET_V2_BUCKET_DEV,$GCS_MARKET_XSOAR_SAAS_BUCKET_DEV"
  stage: unittests-and-validations
  script:
    - section_start "Checks Whether to Trigger a Test Upload"
    - SHOULD_SKIP_TEST_UPLOAD=$(./Utils/should_trigger_test_upload.sh)
    - if [ -z "$SHOULD_SKIP_TEST_UPLOAD" ]; then
    -   echo "No upload-flow related files were modified, skipping upload test"
    -   job-done
    -   exit 0
    - fi
    - echo "Found modified files that should be tested in upload-flow"
    - section_end "Checks Whether to Trigger a Test Upload"

    - section_start "Create Testing Branch"
    - export BRANCH="${CI_COMMIT_BRANCH}-upload_test_branch-${CI_PIPELINE_ID}"
    - echo "${BRANCH}" > "${ARTIFACTS_FOLDER}/test_upload_flow_branch.txt"
    - python3 ./Utils/test_upload_flow/create_test_branch.py -tb "${BRANCH}" -a "${ARTIFACTS_FOLDER}" -g "${GITLAB_PUSH_TOKEN}"

    - echo "Created test branch:${BRANCH}"
    - section_end "Create Testing Branch"

    - section_start "Trigger Test Upload Flow On Testing Branch"
    # retry mechanism for trigger upload pipeline in case it failed because of gitlab connectivity issues.
    - for _ in {1..3}; do
    -   export response=$(./Utils/trigger_test_upload_flow.sh -ct "${GITLAB_SVC_USER_TOKEN}" -b "${BRANCH}" -dz)
    -   export pipeline_id=$(echo $response | jq .id)
    -   if [ "${pipeline_id}" != "null" ] && [ "${pipeline_id}" != \"\" ]; then
    -     break
    -   fi
    -   echo "Sleeping for 10 seconds before retrying"
    -   sleep 10
    - done
    - if [ "${pipeline_id}" == "null" ]; then
    -   echo "Encountered an error when attempting to trigger upload pipeline, received pipeline_id=null, with response = $response"
    -   exit 1
    - fi
    - echo "Successful triggered test upload - ${CI_SERVER_URL}/${CI_PROJECT_NAMESPACE}/content/-/pipelines/$pipeline_id"
    - echo "${pipeline_id}" > "${ARTIFACTS_FOLDER}/test_upload_flow_pipeline_id.txt"
    - section_end "Trigger Test Upload Flow On Testing Branch"

    - section_start "Wait For Upload To Finish"
    - python3 ./Utils/test_upload_flow/wait_for_upload.py -p $pipeline_id -g $GITLAB_API_TOKEN
    - section_end "Wait For Upload To Finish"

    - section_start "Verify Created Testing Bucket"
    - current_storage_base_path="upload-flow/builds/$BRANCH/$pipeline_id/content/packs"
    - python3 ./Utils/test_upload_flow/verify_bucket.py -a "${ARTIFACTS_FOLDER}" -s $GCS_MARKET_KEY -sb $current_storage_base_path -b $ALL_BUCKETS
    - section_end "Verify Created Testing Bucket"
    - job-done
  after_script:
    - !reference [.default-after-script]
    - section_start "Delete Testing Branch"
    - |
      if [ -f "${ARTIFACTS_FOLDER}/test_upload_flow_branch.txt" ]; then
        BRANCH=$(cat "${ARTIFACTS_FOLDER}/test_upload_flow_branch.txt")
        python3 ./Utils/test_upload_flow/delete_test_branch.py -tb "${BRANCH}" -g "${GITLAB_PUSH_TOKEN}"
      fi
    - section_end "Delete Testing Branch"

.server_test_playbooks_results:
  stage: results
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true"'
      when: always
  extends:
    - .default-job-settings
  script:
    - ./Tests/scripts/test_playbooks_results.sh
    - job-done
  artifacts:
    when: always
    expire_in: 30 days
    reports:
      junit:
        - "${ARTIFACTS_FOLDER}/test_playbooks_report.xml"
    paths:
      - "${ARTIFACTS_FOLDER}/test_playbooks_report.xml"
      - ${CI_PROJECT_DIR}/artifacts/*  # restoring the default artifacts path from the job default settings
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*  # restoring the default artifacts path from the job default settings


.e2e_test_results:
  stage: results
  rules:
    - !reference [ .filter-non-nightly-docker-updates-rule, rules ]
    - if: '$IS_NIGHTLY == "true"'
      when: never
  extends:
    - .default-job-settings
  needs:
    - job: xsoar_ng_server_ga
      optional: true
  script:
    - ./Tests/scripts/test_e2e_results.sh
    - job-done
  artifacts:
    when: always
    expire_in: 30 days
    reports:
      junit:
        - "${ARTIFACTS_FOLDER}/e2e_tests_result.xml"
    paths:
      - "${ARTIFACTS_FOLDER}/e2e_tests_result.xml"
      - ${CI_PROJECT_DIR}/artifacts/*  # restoring the default artifacts path from the job default settings
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*  # restoring the default artifacts path from the job default settings


.test_modeling_rule_results:
  stage: results
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NIGHTLY == "true"'
      when: always
  extends:
    - .default-job-settings
  script:
    - ./Tests/scripts/test_modeling_rule_results.sh
    - job-done

xsoar-test_playbooks_results:
  variables:
    SERVER_TYPE: "XSOAR"
    PRODUCT_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    JIRA_ISSUE_TYPE: "XSOAR Dev Bug"
    JIRA_COMPONENT: "Test Failure"
    JIRA_LABELS: '["XSOAR", "nightly"]'
  extends: .server_test_playbooks_results
  needs:
    - job: tests_xsoar_server
    - job: xsoar_ng_server_ga
  dependencies:
    - tests_xsoar_server
    - xsoar_ng_server_ga
  rules:
    - !reference [.filter-non-nightly-docker-updates-rule, rules]
    - if: '$CI_PIPELINE_SOURCE =~ /^(push|contrib)$/'
    - if: '$TRIGGER_TEST_BRANCH == "true"'
    - if: '$IS_NATIVE_NIGHTLY == "true"'
    - if: '$IS_NIGHTLY == "true"'
      when: always

xsiam-test_playbooks_results:
  variables:
    SERVER_TYPE: "XSIAM"
    PRODUCT_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    JIRA_ISSUE_TYPE: "XSOAR Dev Bug"
    JIRA_COMPONENT: "Test Failure"
    JIRA_LABELS: '["XSIAM", "nightly"]'
  extends: .server_test_playbooks_results
  needs:
    - xsiam_server_ga
  dependencies:
    - xsiam_server_ga

xsoar-saas_test_e2e_results:
  variables:
    SERVER_TYPE: "XSOAR"
    PRODUCT_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  extends: .e2e_test_results
  needs:
    - xsoar_ng_server_ga
  dependencies:
    - xsoar_ng_server_ga

xsiam-test_modeling_rule_results:
  variables:
    SERVER_TYPE: "XSIAM"
    PRODUCT_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    JIRA_COMPONENT: "Test Modeling Failure"
    JIRA_ISSUE_TYPE: "XSOAR Dev Bug"
    JIRA_LABELS: '["XSIAM", "nightly"]'
  extends: .test_modeling_rule_results
  needs:
    - xsiam_server_ga
  dependencies:
    - xsiam_server_ga


jobs-done-check-native-nightly:
  extends:
    - .jobs-done-check
  needs:
    - cloning-repositories
    - xsoar-saas-prepare-testing-bucket
    - xsoar_ng_server_ga
    - xsoar-test_playbooks_results
  tags:
    - gke
  rules:
    - if: '$IS_NATIVE_NIGHTLY == "true"'
      when: always
  variables:
    WORKFLOW: 'Native Nightly'


slack-native-notify-nightly-build:
  rules:
    - if: '$IS_NATIVE_NIGHTLY == "true"'
      when: always
  extends:
    - .trigger-slack-notification
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    JOB_NAME: 'fan-in-native-nightly'
    WORKFLOW: 'Native Nightly'
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_PARENT_PIPELINE_ID: $SLACK_PARENT_PIPELINE_ID
    SLACK_PARENT_PROJECT_ID: $SLACK_PARENT_PROJECT_ID
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'false'
    CURRENT_BRANCH_NAME: $INFRA_BRANCH